{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author: [Daniel Puente Viejo](https://www.linkedin.com/in/danielpuenteviejo/)*\n",
    "\n",
    "## **Autogen Multi-Agent Ecosystem: Profile Analysis with Free¬†LLMs**\n",
    "\n",
    "<img src=\"imgs/cover_page.png\" height=\"350\"> \n",
    "\n",
    "Practical example of how to create a multi-agent project with Autogen and completely free¬†LLMs.\n",
    "\n",
    "### **Index:**\n",
    "\n",
    "- <a href='#1'><ins>1 - Libraries</ins></a>\n",
    "- <a href='#2'><ins>2 - Model configuration</ins></a>\n",
    "- <a href='#3'><ins>3 - Termination policy</ins></a>\n",
    "- <a href='#4'><ins>4 - Agents</ins></a>\n",
    "    - <a href='#4.1'><ins>4.1 - User Proxy</ins></a>\n",
    "    - <a href='#4.2'><ins>4.2 - Principal Agents</ins></a>\n",
    "- <a href='#5'><ins>5 - Tools</ins></a>\n",
    "- <a href='#6'><ins>6 - Agent order</ins></a>\n",
    "- <a href='#7'><ins>7 - Multi-agent ecosystem</ins></a>\n",
    "- <a href='#8'><ins>8 - Execution</ins></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='1' style=\"color: skyblue;\">**1 - Libraries**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import autogen\n",
    "from autogen import UserProxyAgent, register_function, AssistantAgent\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='2' style=\"color: skyblue;\">**2 - Model configuration**</a>   \n",
    "\n",
    "\n",
    "In this case, we will create two configurations: one using `llama-3.1-8b-instant` and another using `gemma2-9b-it`. Take a look to the rest of the available models [here](https://console.groq.com/docs/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama 3.1 instant config\n",
    "llama31_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"llama-3.1-8b-instant\",\n",
    "            \"api_key\": os.environ.get(\"GROQ_API_KEY\"),\n",
    "            \"api_type\": \"groq\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# gemma2 config\n",
    "gemma2_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gemma2-9b-it\",\n",
    "            \"api_key\": os.environ.get(\"GROQ_API_KEY\"),\n",
    "            \"api_type\": \"groq\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='3' style=\"color: skyblue;\">**3 - Termination policy**</a>     \n",
    "\n",
    "\n",
    "Autogen requires a mechanism to determine when a process has reached its conclusion. To achieve this, we need to analyze the result and identify a specific pattern. A recommended approach is to program agents to return the word \"TERMINATE\" when they conclude that the query has been successfully resolved. For this purpose, we define the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def termination_message(msg: str) -> bool:\n",
    "    content = msg.get(\"content\", \"\").lower()\n",
    "    return \"terminate\" in content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='4' style=\"color: skyblue;\">**4 - Agents**</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.1' style=\"color: azure;\">**4.1 - User Proxy**</a>   \n",
    "\n",
    "Let's begin with the UserProxyAgent. It acts as an intermediary, representing a human user within a multi-agent system. Its primary function is to execute code and provide feedback to other agents, enabling human-in-the-loop interactions during automated processes. In this case, it is only responsible for executing tools and returning the results to the appropriate agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user proxy agent that executes tool calls.\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=False,\n",
    "    is_termination_msg=termination_message,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"use_docker\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='4.2' style=\"color: azure;\">**4.2 - Principal Agents**</a>   \n",
    "\n",
    "The idea is straightforward: it involves a group of agents designed to analyze a CV or profile, each specializing in a specific task. This group will consist of four agents:\n",
    "\n",
    "* CV Analyzer üìä: This agent specializes in analyzing the input CV or profile document. Its task is to extract the most relevant information from the document, such as professional experience, education, and notable achievements, providing a structured summary of the candidate's profile.\n",
    "* Skills Extractor üîß: This agent is responsible for extracting the key skills from the CV. It identifies competencies such as programming languages, technical proficiencies, or soft skills and returns them in a concise, comma-separated list for easy reference.\n",
    "* Courses Recommender üë®‚Äçüéì: This agent matches the extracted skills with a database of available courses. Its goal is to recommend courses that can help the candidate enhance or expand their skill set, providing tailored suggestions based on their profile.\n",
    "* Resolution Checker üéØ: The role of this agent is to determine whether the user's query has been fully resolved. It reviews the outputs of the other agents and, if the task is completed, it is responsible for forming the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Agent 1: CV Analyser --\n",
    "cv_analyser = AssistantAgent(\n",
    "    name=\"CV Analyser\",\n",
    "    description=\"It analyzes the input it giving the most relevant information of the document.\",\n",
    "    system_message=\"\"\"You must return an analysis of the input file.\n",
    "    Other details for your answer:\n",
    "    - Do not responde any piece of code.\n",
    "    - Do not recommend courses just analyse the input file.\"\"\",\n",
    "    llm_config=llama31_config,\n",
    ")\n",
    "\n",
    "## -- Agent 2: Skills Extractor --\n",
    "skills_extractor = AssistantAgent(\n",
    "    name=\"Skills Extractor\",\n",
    "    description=\"Returns a list of the candidates skills\",\n",
    "    system_message=\"\"\"Your task is to extract the main skills from the input received.\n",
    "    You must return the skills as a comma-separated list. For example: 'Python, Java, SQL'. Do not add more information, just the list of skills in the specified format.\n",
    "    Other details for your answer:\n",
    "    - Do not responde any piece of code.\n",
    "    - Do not recommend courses just return the skills as a comma-separated list of the input file.\"\"\",\n",
    "    llm_config=llama31_config,\n",
    ")\n",
    "\n",
    "## -- Agent 3: Courses Recommender --\n",
    "courses_recommender = AssistantAgent(\n",
    "    name=\"Courses recommender\",\n",
    "    description=\"The goal is to recommend courses. Read the courses from `data/courses.txt` and return the courses that match the skills of the input file.\",\n",
    "    system_message=\"\"\"The goal is to recommend courses, for that follow these steps:\n",
    "    1) Read the list of courses from `data/courses.txt` (use `read_txt_courses` tool).\n",
    "    2) Combine the list of courses with the profile of the candidate.\n",
    "    3) Return the courses that match the skills of the candidate.\n",
    "    Other details for your answer: Do not responde any piece of code.\"\"\",\n",
    "    llm_config=llama31_config,\n",
    ")\n",
    "\n",
    "# -- Agent 4: Resolution Checker Agent --\n",
    "resolution_checker = AssistantAgent(\n",
    "    name=\"Resolution Checker Agent\",\n",
    "    description=\"Checks if the user's query has been resolved. If resolved, respond with 'TERMINATE', otherwise respond with 'CONTINUE'. Do not give more information just the word 'CONTINUE' or 'TERMINATE'.\",\n",
    "    system_message=\"\"\"You should respond with 'TERMINATE' if the query has been resolved. Otherwise, respond with 'CONTINUE'. Do not add more information, just the word 'CONTINUE'.\n",
    "    Try to be resolute, do not reply 'TERMINATE' if the initial query has not been resolved.\n",
    "    **IMPORTANT**: Only respond with 'TERMINATE' if the query has been resolved, otherwise respond with 'CONTINUE'. If the answer is 'TERMINATE', you must answer 'TERMINATE' + generate a complete answer to the user's query considering all the information given by all the agents to generate the final answer.\"\"\",\n",
    "    llm_config=gemma2_config,\n",
    "    is_termination_msg=termination_message,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='5' style=\"color: skyblue;\">**5 - Tools**</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple Python function that reads a¬†`.txt` file. The use of type annotations is important to clearly define the expected input and output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool: Read CV from File\n",
    "def read_txt(path: str) -> str:\n",
    "    with open(path, \"r\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to configure each agent to allow the use of this tool. The tool is executed by the User Proxy, so we need to specify the caller, which is the agent that can access the tool, and the executor, which will be the User Proxy. Additionally, we must provide a name and description for the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the read_txt function with the assistant agent.\n",
    "register_function(\n",
    "    read_txt,\n",
    "    caller=cv_analyser,\n",
    "    executor=user_proxy,\n",
    "    name=\"read_txt_cv_analyse\",\n",
    "    description=\"Read the profile of the user\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    read_txt,\n",
    "    caller=courses_recommender,\n",
    "    executor=user_proxy,\n",
    "    name=\"read_txt_courses\",\n",
    "    description=\"Read available courses and/or the profile of the user\",\n",
    ")\n",
    "\n",
    "register_function(\n",
    "    read_txt,\n",
    "    caller=skills_extractor,\n",
    "    executor=user_proxy,\n",
    "    name=\"read_txt_cv_skills\",\n",
    "    description=\"Read the profile of the user\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='6' style=\"color: skyblue;\">**6 - Agent order**</a>  \n",
    "\n",
    "There are different ways to manage a group of agents. Let's review the most common conversational patterns:\n",
    "\n",
    "* **Round Robin:** Agents follow a predefined order, regardless of the query. The system executes them sequentially according to this order.\n",
    "* **Random**: The speaker selection is random. This approach is not highly recommended due to its lack of structure.\n",
    "* **Manual**: When a query is made, the system starts, and agent selection is performed manually by a human. After one agent completes its task, the system asks the user to specify the next agent, continuing until the query is considered resolved.\n",
    "* **Auto**: An LLM decides the next speaker based on the context of the conversation and the description of each agent.\n",
    "* **Hybrid**: A combination of manual and automated approaches. You can establish a set of rules to allow the LLM manager to select the next agent or specify which agents will act depending on predefined conditions.\n",
    " \n",
    "\n",
    "Of course, there are more complex ways to manage agent ecosystems, but we will focus on these examples to keep the article concise and help you understand the concept. \n",
    "\n",
    "We will focus on the last type, **hybrid**. To implement this, we need to create a custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GroupChatManager to oversee the conversation\n",
    "def custom_speaker_selection(last_speaker, groupchat):\n",
    "    \"\"\"\n",
    "    Function to change the agent selection logic and customize the speaker selection.\n",
    "\n",
    "    Args:\n",
    "    last_speaker (Agent): The last agent that spoke.\n",
    "    groupchat (GroupChat): The group chat object.\n",
    "\n",
    "    Returns:\n",
    "    Agent: The agent that will speak next.\n",
    "    \"\"\"\n",
    "    agents_to_check = [\"cv analyser\", \"skills extractor\", \"courses recommender\"]\n",
    "\n",
    "    # Extract the last and penultimate messages\n",
    "    last_message = groupchat.messages[-1]\n",
    "    penultimate_message = groupchat.messages[-2] if len(groupchat.messages) > 1 else None\n",
    "\n",
    "    # Extract the names of the last and penultimate speakers\n",
    "    last_speaker_name = last_speaker.name.lower()\n",
    "    penultimate_speaker_name = penultimate_message['name'] if penultimate_message else None\n",
    "\n",
    "    ### If the agent has made a tool call, call the 'User'\n",
    "    if last_message.get(\"tool_calls\", \"\"):\n",
    "        return next(agent for agent in groupchat.agents if agent.name == \"User\")\n",
    "\n",
    "    ### If the last speaker was the 'User' and the penultimate speaker was not the user or the Resolution Checker Agent, call the penultimate speaker\n",
    "    ### Example: Skills Extractor makes use of a tool, so it call the 'User' agent. The 'User' agent then calls the 'Skills Extractor' to continue with the task it was doing.\n",
    "    if last_speaker_name == \"user\" and penultimate_speaker_name and penultimate_speaker_name.lower() not in [\"user\", \"resolution checker agent\"]:\n",
    "        return next(agent for agent in groupchat.agents if agent.name == penultimate_speaker_name)\n",
    "\n",
    "    ### The an agent has given an answer, check if the quey is complete. For that call the 'Resolution Checker Agent'\n",
    "    ### Example: The 'Courses Recommender' agent has given an answer, so the 'Resolution Checker Agent' is called to check if the query is complete.\n",
    "    if last_speaker_name in agents_to_check:\n",
    "        return next(agent for agent in groupchat.agents if agent.name == \"Resolution Checker Agent\")\n",
    "\n",
    "    ### If no condition is met, leave the automatic configuration so that the next agent selection is based on an LLM.\n",
    "    return 'auto'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='7' style=\"color: skyblue;\">**7 - Multi-agent ecosystem**</a>   \n",
    "\n",
    "The final step before interacting with the system is to create the engine that handles everything we have constructed.\n",
    "\n",
    "The group chat specifies the agents participating in the system, how to select the next agent, whether an agent can speak consecutively or not, and the focus criteria for agent selection. \n",
    "\n",
    "The manager can be defined as the entity that will manage the whole system. It requires the previously defined group chat, specifies that code execution does not use Docker, determines the LLM configuration for agent selection, and defines the termination message to signal when the process is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the group chat\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[\n",
    "        user_proxy,\n",
    "        cv_analyser,\n",
    "        skills_extractor,\n",
    "        courses_recommender,\n",
    "        resolution_checker,\n",
    "    ],\n",
    "    messages=[],\n",
    "    allow_repeat_speaker=True,\n",
    "    speaker_selection_method=custom_speaker_selection, # Other options are: \"round_robin\", \"random\", \"manual\", \"auto\"\n",
    "    role_for_select_speaker_messages=\"system\"\n",
    ")\n",
    "\n",
    "# Finally, create the group chat manager\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat,\n",
    "    code_execution_config={\"use_docker\": False},\n",
    "    llm_config=gemma2_config,\n",
    "    is_termination_msg=termination_message,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='8' style=\"color: skyblue;\">**8 - Execution**</a>\n",
    "\n",
    "First, we define the file path variable for the CV. Next, we create the message specifying what we want the system to do. Some example messages are provided to illustrate different functionalities of the system.  \n",
    "\n",
    "Finally, we initiate the chat using the User Proxy, passing the manager to control the conversation, the message to be processed, and the maximum number of turns. Setting a high value for max_turns ensures that even if the termination criteria are not met, the conversation will eventually end without being cut off prematurely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "Recommend courses for the profile data/cv.txt\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Courses recommender\n",
      "\u001b[0m\n",
      "\u001b[33mCourses recommender\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_44re): read_txt_courses *****\u001b[0m\n",
      "Arguments: \n",
      "{\"path\":\"data/cv.txt\"}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_51mv): read_txt_courses *****\u001b[0m\n",
      "Arguments: \n",
      "{\"path\":\"data/courses.txt\"}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION read_txt_courses...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION read_txt_courses...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_44re) *****\u001b[0m\n",
      "Daniel Puente Viejo\n",
      "+34 638 097 547\n",
      "daniel.puenteviejo@gmail.com\n",
      "https://github.com/DanielPuentee | https://www.linkedin.com/in/danielpuenteviejo | https://medium.com/@daniel.puenteviejo | https://huggingface.co/D0k-tor\n",
      "\n",
      "---\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "\n",
      "NTT Data\n",
      "‚û¢ Clients: Cepsa, Repsol, Unsere Gr√ºne Glasfaser, RED.es, BBVA, NTT Data (Intern client)\n",
      "\n",
      "External Senior AI Engineer at Repsol; Bilbao, Spain\n",
      "*10/2024 - Present*\n",
      "- Led the design of Repsol's cross AI Multi-Agent platform and LLMOps platform, including LLM API Management, to support scalable generative AI applications (Azure-oriented solutions).\n",
      "- Designed and managed the technical design of multiple Gen AI MVPs, driving innovation in all business areas.\n",
      "\n",
      "Generative AI II Engineer; Bilbao, Spain\n",
      "*05/2024 - 10/2024*\n",
      "- Developer of a Generative AI platform on AWS, valued at ‚Ç¨25M, for the Spanish Ministry of Digital Transformation (AWS Architecture, RAG, clause extraction, plagiarism detection...).\n",
      "- Reduced amendment generation time by 95% by developing LLM and OCR techniques implemented in AWS.\n",
      "\n",
      "Generative AI I Engineer; Bilbao, Spain\n",
      "*09/2023 - 05/2024*\n",
      "- Reduced time for legal information search, generation, and question answering by 90% through the creation of a RAG system using Azure Cognitive Services (Repsol's first generative AI use case).\n",
      "- Led the improvement of executive information search time through a RAG system using Dolffia and OpenAI Whisper.\n",
      "\n",
      "Junior Artificial Intelligence Engineer (Intern); Bilbao, Spain\n",
      "*09/2022 - 07/2023*\n",
      "- Improved explainability and precision (~80%) of credit fraud detection by applying Azure ML and GNN.\n",
      "- Encouraged learning by creating an AI initiative with over 20 current members.\n",
      "  - Developed a contact detection algorithm for the NFL using Azure ML.\n",
      "  - Applied diffusion algorithms for automatic image description.\n",
      "\n",
      "Navarra University\n",
      "Data Science Professor; Pamplona, Spain\n",
      "*09/2023 - Present*\n",
      "- Develop Generative AI course for BBVA Data Scientists (RAG, LLM fine-tuning, and RAG evaluation).\n",
      "- Professor of Data Science in the Business + Data Analytics and Economics + Data Analytics double degree programmes.\n",
      "\n",
      "Mondragon University\n",
      "‚û¢ Clients: BBVA, Ormazabal, Sener, Laboral Kutxa, Mondragon Corporation, Lookiero‚Ä¶\n",
      "\n",
      "Student Data Scientist; Bilbao, Spain\n",
      "*09/2019 - 12/2022*\n",
      "- Achieved 0% risk of lithium-ion battery explosion by developing LSTM + GAN models.\n",
      "- Reduced cost by 15% and improved engine design efficiency by 2% using evolutionary algorithms and RL.\n",
      "- Developed an automatic fashion look recommendation system using graph neural networks (GNN).\n",
      "- 42%-time reduction of Monte Carlo simulations using Recurrent Neural Networks.\n",
      "\n",
      "---\n",
      "\n",
      "EDUCATION\n",
      "\n",
      "Master of Science in Artificial Intelligence - UNIR; Online\n",
      "*10/2023 - 08/2024*\n",
      "Final Mark: 9,5/10 ¬∑ A+ | MSc Thesis: Implementation and Evaluation of a RAG System for the Resolution of Legal Queries.\n",
      "\n",
      "Bachelor of Science in AI & Data Analytics - Mondragon University (1¬∫ Promotion); Bilbao, Spain\n",
      "*09/2019 - 07/2023*\n",
      "Final Mark: 9,0/10 ¬∑ A | BSc Thesis: Simulation of a graph-based fraud detection algorithm deployed in a production Azure.\n",
      "\n",
      "Bachelor of Science in Mathematical Sciences - Essex University; Colchester, England\n",
      "*04/2022 - 07/2022*\n",
      "Final Mark: 8,6/10 ¬∑ B+\n",
      "\n",
      "---\n",
      "\n",
      "LANGUAGES\n",
      "- Spanish (Native)\n",
      "- English (Cambridge Certificate Advanced English, C1)\n",
      "- Basque (B2)\n",
      "\n",
      "---\n",
      "\n",
      "SKILLS\n",
      "- Programming: Python ‚Ä¢ R ‚Ä¢ SQL\n",
      "- AI Frameworks: Langchain ‚Ä¢ CrewAI ‚Ä¢ Ollama ‚Ä¢ Hugging Face ‚Ä¢ Pytorch\n",
      "- Cloud: Azure ‚Ä¢ AWS ‚Ä¢ Azure AI Services ‚Ä¢ Bedrock\n",
      "- Other utilities: Finetuning ‚Ä¢ RAG ‚Ä¢ CUDA ‚Ä¢ Git ‚Ä¢ Databricks ‚Ä¢ GNN ‚Ä¢ QLoRA\n",
      "\n",
      "---\n",
      "\n",
      "AWARDS & HONOURS\n",
      "Certifications and Personal Projects\n",
      "- Completed over 30 courses in AI, including Microsoft Certified: DP-100, AI-102, DP-900 & AI-900.\n",
      "- Selected among the 5 best Bachelor Thesis out of 300 candidates in the Mondragon Corporation Awards.\n",
      "- Selected as one of around 250 participants in the Bizkaia Talent program ‚Äúattracting young talents‚Äù.\n",
      "- Scholarship for academic excellence (2019).\n",
      "\n",
      "---\n",
      "\n",
      "\u001b[32m**************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_51mv) *****\u001b[0m\n",
      "1. Machine Learning\n",
      "- Machine Learning Crash Course - Google Developers\n",
      "- Supervised Machine Learning: Regression and Classification - Coursera\n",
      "- Deep Learning Specialization - DeepLearning.AI\n",
      "- Machine Learning Specialization - Coursera\n",
      "- Machine Learning for Healthcare - Stanford University\n",
      "\n",
      "2. Natural Language Processing (NLP)\n",
      "- Natural Language Processing Specialization - Coursera\n",
      "- Natural Language Processing with Attention Models - Coursera\n",
      "- Natural Language Processing with Classification and Vector Spaces - Coursera\n",
      "- Speech Processing: Introduction to Speech Recognition - Georgia Tech\n",
      "- Building Conversational Experiences with Dialogflow - Coursera\n",
      "\n",
      "3. Computer Vision\n",
      "- Computer Vision Basics - Coursera\n",
      "- Convolutional Neural Networks - Coursera\n",
      "- Advanced Computer Vision with TensorFlow - Coursera\n",
      "- Generative Adversarial Networks (GANs) Specialization - Coursera\n",
      "- Self-Driving Cars Specialization - Coursera\n",
      "\n",
      "4. AI for Business and Decision Making\n",
      "- AI For Everyone - Coursera\n",
      "- Business Analytics Specialization - Coursera\n",
      "- AI in Marketing - Coursera\n",
      "- AI for Supply Chain Management - Coursera\n",
      "- AI Ethics: Global Perspectives - edX\n",
      "\n",
      "\u001b[32m**************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Courses recommender\n",
      "\u001b[0m\n",
      "\u001b[33mCourses recommender\u001b[0m (to chat_manager):\n",
      "\n",
      "Based on the profile of Daniel Puente Viejo, we can recommend the following courses to him:\n",
      "\n",
      "1. Machine Learning:\n",
      " - \"Deep Learning Specialization\"\n",
      " - \"Machine Learning for Healthcare - Stanford University\"\n",
      "2. Natural Language Processing (NLP):\n",
      " - \"Natural Language Processing with Attention Models\"\n",
      " - \"Building Conversational Experiences with Dialogflow\"\n",
      "3. Computer Vision:\n",
      " - \"Generative Adversarial Networks (GANs) Specialization\"\n",
      " - \"Convolutional Neural Networks\"\n",
      "4. AI for Business and Decision Making:\n",
      " - \"AI For Everyone\"\n",
      " - \"AI in Marketing\"\n",
      " - \"AI Ethics: Global Perspectives\"\n",
      "\n",
      "We can recommend these courses because they match Daniel's interests and skills in AI and machine learning, and they align with his career goals in the field.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Resolution Checker Agent\n",
      "\u001b[0m\n",
      "\u001b[33mResolution Checker Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "TERMINATE \n",
      "\n",
      "Based on the provided profile, here are some course recommendations tailored to Daniel Puente Viejo's experience and interests:\n",
      "\n",
      "**Deepening his Expertise:**\n",
      "\n",
      "* **Deep Learning Specialization (DeepLearning.AI):** Given his experience leading the design of Repsol's cross AI Multi-Agent platform and LLMOps platform (oriented towards Azure solutions), this specialization will provide advanced knowledge in deep learning architectures and applications.  \n",
      "* **Machine Learning for Healthcare (Stanford University):**  His experience at NTT Data working on generative AI for the Spanish Ministry of Digital Transformation suggests an interest in applying AI to real-world problems.  This course could further develop his skills in this area.\n",
      "* **Generative Adversarial Networks (GANs) Specialization (Coursera):**  His work on generative AI platforms and his experience using diffusion algorithms for image description point to a strong interest in generative models.  This specialization will deepen his understanding of GANs, a powerful class of generative models.\n",
      "\n",
      "**Expanding Skillsets:**\n",
      "\n",
      "* **Natural Language Processing with Attention Models (Coursera):** Given his work on RAG systems and interest in LLMs, this course will provide valuable insights into attention mechanisms, a key component of modern NLP models.\n",
      "* **Building Conversational Experiences with Dialogflow (Coursera):**  His experience with LLMs and his role at Navarra University developing an AI initiative suggest an interest in building practical AI applications. This course will equip him with tools and knowledge to create conversational agents.  \n",
      "* **Convolutional Neural Networks (Coursera):**  Since he has worked with Computer Vision, a deeper understanding of convolutional neural networks, a fundamental building block of many computer vision models, would be beneficial.\n",
      "* **AI For Everyone (Coursera):** This course will provide a broad understanding of AI concepts and applications, which can be valuable for his work in driving AI innovation across business areas at Repsol.\n",
      "* **AI Ethics: Global Perspectives (edX):** As Daniel takes on leadership roles in developing and deploying AI systems, understanding the ethical implications of these technologies is crucial. This course will equip him with the knowledge to navigate the complex ethical landscape of AI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# File path for the CV\n",
    "cv_file_path = \"data/cv.txt\"\n",
    "\n",
    "# Define the message to be sent to the manager\n",
    "message = f\"Recommend courses for the profile {cv_file_path}\"\n",
    "# message = f\"Analyse the following profile: {cv_file_path}.\"\n",
    "# message = f\"Extract skills in comma-separated format based on the following profile: {cv_file_path}.\"\n",
    "# message = f\"Recommends courses for the profile {cv_file_path}. Return also the profile skills in a list.\"\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    recipient=manager,\n",
    "    message=message,\n",
    "    max_turns=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User', 'Courses recommender', 'User', 'Courses recommender', 'Resolution Checker Agent']\n"
     ]
    }
   ],
   "source": [
    "# See the agent order\n",
    "agent_order = [x['name'] for x in chat_result.chat_history]\n",
    "print(agent_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERMINATE \n",
      "\n",
      "Based on the provided profile, here are some course recommendations tailored to Daniel Puente Viejo's experience and interests:\n",
      "\n",
      "**Deepening his Expertise:**\n",
      "\n",
      "* **Deep Learning Specialization (DeepLearning.AI):** Given his experience leading the design of Repsol's cross AI Multi-Agent platform and LLMOps platform (oriented towards Azure solutions), this specialization will provide advanced knowledge in deep learning architectures and applications.  \n",
      "* **Machine Learning for Healthcare (Stanford University):**  His experience at NTT Data working on generative AI for the Spanish Ministry of Digital Transformation suggests an interest in applying AI to real-world problems.  This course could further develop his skills in this area.\n",
      "* **Generative Adversarial Networks (GANs) Specialization (Coursera):**  His work on generative AI platforms and his experience using diffusion algorithms for image description point to a strong interest in generative models.  This specialization will deepen his understanding of GANs, a powerful class of generative models.\n",
      "\n",
      "**Expanding Skillsets:**\n",
      "\n",
      "* **Natural Language Processing with Attention Models (Coursera):** Given his work on RAG systems and interest in LLMs, this course will provide valuable insights into attention mechanisms, a key component of modern NLP models.\n",
      "* **Building Conversational Experiences with Dialogflow (Coursera):**  His experience with LLMs and his role at Navarra University developing an AI initiative suggest an interest in building practical AI applications. This course will equip him with tools and knowledge to create conversational agents.  \n",
      "* **Convolutional Neural Networks (Coursera):**  Since he has worked with Computer Vision, a deeper understanding of convolutional neural networks, a fundamental building block of many computer vision models, would be beneficial.\n",
      "* **AI For Everyone (Coursera):** This course will provide a broad understanding of AI concepts and applications, which can be valuable for his work in driving AI innovation across business areas at Repsol.\n",
      "* **AI Ethics: Global Perspectives (edX):** As Daniel takes on leadership roles in developing and deploying AI systems, understanding the ethical implications of these technologies is crucial. This course will equip him with the knowledge to navigate the complex ethical landscape of AI.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the last result\n",
    "print(chat_result.chat_history[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCrew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
